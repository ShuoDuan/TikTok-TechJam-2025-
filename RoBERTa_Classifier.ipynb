{"cells":[{"cell_type":"code","execution_count":80,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1756573709324,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"CrIZXEsL5VrI"},"outputs":[],"source":["import os\n","import random\n","from dataclasses import dataclass\n","from typing import List, Dict, Optional, Tuple\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n","\n","import torch\n","from torch.utils.data import Dataset\n","\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    Trainer,\n","    TrainingArguments,\n","    EarlyStoppingCallback,\n",")\n"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"executionInfo":{"elapsed":20426,"status":"ok","timestamp":1756573730594,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"jpuWp4ZR5eDa","outputId":"3ddfd6da-2edd-4de7-87cc-06a62054a8c2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-ec1e1154-1efe-4d88-9ae0-c87b9a95bf94\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-ec1e1154-1efe-4d88-9ae0-c87b9a95bf94\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving finalllll_dataset.csv to finalllll_dataset (4).csv\n","Shape: (4962, 3)\n","Columns: ['name', 'text', 'label']\n"]},{"output_type":"execute_result","data":{"text/plain":["               name                                               text  \\\n","0        Will Payne                        Poor selection of shingles.   \n","1      ben franklin  You have to be kidding me, 2 and a half hours ...   \n","2  Courtney Lumpkin  This place is terrible. They had a patient tha...   \n","3       Cathy Smith  The movers were very polite and on time. Howev...   \n","4  Jade Kleeschulte  Never used them because an estimate to move it...   \n","5        Chuck Blue  I'm a life member of the VFW, a past post comm...   \n","6    Mikemike Fuqua  You take product working and get product back ...   \n","7       chip linton  They are only out for your money not to help a...   \n","8         Gun Wench  They won't let me give less than 1 star. Sign ...   \n","9              GiGi  Decided to look into this, they recommended pr...   \n","\n","         label  \n","0  Good Review  \n","1         Rant  \n","2         Rant  \n","3  Good Review  \n","4         Rant  \n","5         Rant  \n","6         Rant  \n","7         Rant  \n","8         Rant  \n","9         Rant  "],"text/html":["\n","  <div id=\"df-70d1ffea-d8dd-429b-a0ef-d3d8152a4650\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Will Payne</td>\n","      <td>Poor selection of shingles.</td>\n","      <td>Good Review</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ben franklin</td>\n","      <td>You have to be kidding me, 2 and a half hours ...</td>\n","      <td>Rant</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Courtney Lumpkin</td>\n","      <td>This place is terrible. They had a patient tha...</td>\n","      <td>Rant</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Cathy Smith</td>\n","      <td>The movers were very polite and on time. Howev...</td>\n","      <td>Good Review</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Jade Kleeschulte</td>\n","      <td>Never used them because an estimate to move it...</td>\n","      <td>Rant</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Chuck Blue</td>\n","      <td>I'm a life member of the VFW, a past post comm...</td>\n","      <td>Rant</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Mikemike Fuqua</td>\n","      <td>You take product working and get product back ...</td>\n","      <td>Rant</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>chip linton</td>\n","      <td>They are only out for your money not to help a...</td>\n","      <td>Rant</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Gun Wench</td>\n","      <td>They won't let me give less than 1 star. Sign ...</td>\n","      <td>Rant</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>GiGi</td>\n","      <td>Decided to look into this, they recommended pr...</td>\n","      <td>Rant</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70d1ffea-d8dd-429b-a0ef-d3d8152a4650')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-70d1ffea-d8dd-429b-a0ef-d3d8152a4650 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-70d1ffea-d8dd-429b-a0ef-d3d8152a4650');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-ca19cc0d-9a0e-4a2b-8224-6c57359ecd06\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca19cc0d-9a0e-4a2b-8224-6c57359ecd06')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-ca19cc0d-9a0e-4a2b-8224-6c57359ecd06 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 4962,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4321,\n        \"samples\": [\n          \"Chantaye Robinson-Jones\",\n          \"Shirley Drosyk\",\n          \"Lauryn Black\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4858,\n        \"samples\": [\n          \"Kristina listens to you and asks questions to figure out what is going on. She cares for her patients.\",\n          \"I\\u00a1\\u00afve been working on building my playlist lately!\",\n          \"Awesome product!! Go here!! www.savingscentral.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Rant\",\n          \"Spam\",\n          \"Irrelevant Content\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":81}],"source":["from google.colab import files\n","uploaded = files.upload()  # choose reviews_cleaned.csv\n","\n","import pandas as pd\n","fname = next(iter(uploaded))  # first uploaded file\n","# Ensure the correct columns are read\n","df = pd.read_csv(fname, encoding=\"latin-1\")\n","\n","# Drop the rating column as requested\n","if 'rating' in df.columns:\n","    df = df.drop('rating', axis=1)\n","\n","# Handle missing values in critical columns ('text' and 'label') by dropping rows\n","df.dropna(subset=['text', 'label'], inplace=True)\n","\n","\n","print(\"Shape:\", df.shape)\n","print(\"Columns:\", list(df.columns))\n","df.head(10)"]},{"cell_type":"code","execution_count":82,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1756573730631,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"fp0YYmdm5gfQ"},"outputs":[],"source":["def set_seed(seed: int = 42):\n","    random.seed(seed); np.random.seed(seed)\n","    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":83,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1756573733121,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"dZ1kPK685kyr"},"outputs":[],"source":["class ReviewsDataset(Dataset):\n","    \"\"\"Torch dataset for text classification with Hugging Face tokenizers.\"\"\"\n","    def __init__(\n","        self,\n","        df: pd.DataFrame,\n","        tokenizer: AutoTokenizer,\n","        text_col: str,\n","        label_col: Optional[str],\n","        max_len: int,\n","        label2id: Optional[Dict[str, int]] = None,\n","        is_train: bool = True,\n","    ):\n","        self.df = df.reset_index(drop=True)\n","        self.tokenizer = tokenizer\n","        self.text_col = text_col\n","        self.label_col = label_col if label_col in df.columns else None\n","        self.max_len = max_len\n","        self.is_train = is_train\n","        self.label2id = label2id\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        text = \"\" if pd.isna(row[self.text_col]) else str(row[self.text_col])\n","\n","        enc = self.tokenizer(\n","            text, # Use only text\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=self.max_len,\n","            return_tensors=\"pt\",\n","        )\n","\n","        item = {k: v.squeeze(0) for k, v in enc.items()}\n","        if self.is_train and self.label_col is not None:\n","            y = row[self.label_col]\n","            # Check for NaN values and skip them\n","            if pd.isna(y):\n","                # Use first label as default for NaN values\n","                y = list(self.label2id.keys())[0] if self.label2id else 0\n","            if self.label2id is not None:\n","                y = self.label2id[str(y)]\n","            item[\"labels\"] = torch.tensor(int(y), dtype=torch.long)\n","        return item"]},{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":600,"status":"ok","timestamp":1756573733954,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"zCpMZF246DK0"},"outputs":[],"source":["def build_label_maps(df: pd.DataFrame, label_col: str, label_list: Optional[List[str]] = None):\n","    \"\"\"Create label <-> id maps. If label_list supplied, follow that order.\"\"\"\n","    if label_list is None:\n","        # Filter out NaN values and auto from data (sorted for reproducibility)\n","        label_list = sorted(df[label_col].dropna().astype(str).unique().tolist())\n","    label2id = {lbl: i for i, lbl in enumerate(label_list)}\n","    id2label = {i: lbl for lbl, i in label2id.items()}\n","    return label2id, id2label, label_list\n","\n","def compute_metrics_fn(id2label: Dict[int, str]):\n","    \"\"\"Returns a compute_metrics callable that Trainer will use.\"\"\"\n","    def _compute_metrics(eval_pred):\n","        logits, labels = eval_pred\n","        preds = logits.argmax(axis=1)\n","        acc = accuracy_score(labels, preds)\n","        f1_macro = f1_score(labels, preds, average=\"macro\")\n","        return {\"accuracy\": acc, \"f1_macro\": f1_macro}\n","    return _compute_metrics"]},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1756573735087,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"J3i4HM2c6Gz6"},"outputs":[],"source":["class WeightedTrainer(Trainer):\n","    \"\"\"class-weighted loss to handle imbalance.\"\"\"\n","    def __init__(self, class_weights: Optional[torch.Tensor] = None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.class_weights = class_weights\n","\n","    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None): # Add num_items_in_batch\n","        labels = inputs.get(\"labels\")\n","        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n","        logits = outputs.get(\"logits\")\n","        if labels is not None:\n","            if self.class_weights is not None:\n","                self.class_weights = self.class_weights.to(logits.device)\n","                loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n","            else:\n","                loss_fct = torch.nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1)) # Use logits.size(-1) to get the number of classes\n","        else:\n","            loss = outputs[\"loss\"] if \"loss\" in outputs else None\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1756573735095,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"tEOLuLBe6Kb2"},"outputs":[],"source":["def predict_proba_texts(\n","    tokenizer: AutoTokenizer, # Add tokenizer as an explicit argument\n","    trainer: Trainer,\n","    texts: List[str],\n","    max_len: int = 128,\n",") -> np.ndarray:\n","    \"\"\"Return softmax probabilities (N x C) for a list of raw texts.\"\"\"\n","    model = trainer.model\n","    model.eval()\n","\n","    all_probs = []\n","    with torch.no_grad():\n","        for i in range(0, len(texts), 64):\n","            batch_texts = texts[i:i+64]\n","            enc = tokenizer(\n","                batch_texts, truncation=True, padding=True, max_length=max_len, return_tensors=\"pt\"\n","            )\n","            # Get the model's device\n","            device = next(model.parameters()).device\n","            enc = {k: v.to(device) for k, v in enc.items()}\n","            # Access logits from the dictionary returned by the model\n","            outputs = model(**enc)\n","            logits = outputs['logits']\n","            probs = torch.softmax(logits, dim=-1).cpu().numpy()\n","            all_probs.append(probs)\n","    return np.vstack(all_probs)\n","\n","def predict_proba_df(\n","    tokenizer: AutoTokenizer, # Add tokenizer as an explicit argument\n","    trainer: Trainer,\n","    df: pd.DataFrame,\n","    id2label: Dict[int, str], # Add id2label as an argument\n","    text_col: str = \"text\",\n","    max_len: int = 128,\n",") -> pd.DataFrame:\n","    \"\"\"Attach softmax probabilities and predicted label names to a dataframe.\"\"\"\n","    probs = predict_proba_texts(tokenizer, trainer, df[text_col].astype(str).fillna(\"\").tolist(), max_len=max_len) # Pass tokenizer to predict_proba_texts\n","    # Use the passed id2label dictionary\n","    pred_ids = probs.argmax(axis=1)\n","    pred_labels = [id2label[int(i)] for i in pred_ids]\n","    out = df.copy()\n","    out[\"pred_label\"] = pred_labels\n","    for i in range(probs.shape[1]):\n","        out[f\"p_{id2label[i]}\"] = probs[:, i]\n","    return out"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1756573735224,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"UbaIIKpP6N7S"},"outputs":[],"source":["# Define column names first\n","TEXT_COL  = \"text\"                             # change if your text column is different\n","LABEL_COL = \"label\" if \"label\" in df.columns else \"label_rule\"\n","# RATING_COL = \"rating\" # Define rating column name - removed as rating is dropped\n","\n","# Split the data into train, test, val\n","from sklearn.model_selection import train_test_split\n","\n","# Filter out rows with NaN labels before splitting\n","df_clean = df.dropna(subset=[LABEL_COL])\n","\n","# First split: separate out test set (20%)\n","train_val, test = train_test_split(df_clean, test_size=0.2, random_state=42)\n","\n","# Second split: split remaining data into train (64%) and val (16%)\n","train, val = train_test_split(train_val, test_size=0.2, random_state=42)\n","\n","# maps, tokenizer, datasets\n","label2id, id2label, _ = build_label_maps(train, LABEL_COL)\n","tok     = AutoTokenizer.from_pretrained(\"roberta-base\", use_fast=True)\n","# Update ReviewsDataset initialization to not include rating_col\n","train_ds = ReviewsDataset(train, tok, TEXT_COL, LABEL_COL, max_len=128, label2id=label2id, is_train=True)\n","val_ds   = ReviewsDataset(val,   tok, TEXT_COL, LABEL_COL, max_len=128, label2id=label2id, is_train=True)"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1756573735245,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"39e93628","outputId":"d9543d18-9198-446a-dab6-62cd4d971b0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Class weights: {'Advertisement': np.float64(8.246753246753247), 'Good Review': np.float64(0.25594518339379285), 'Irrelevant Content': np.float64(3.097560975609756), 'Rant': np.float64(1.8513119533527698), 'Spam': np.float64(9.202898550724637)}\n","Weights tensor: tensor([8.2468, 0.2559, 3.0976, 1.8513, 9.2029])\n"]}],"source":["from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","import torch\n","\n","# Calculate class weights\n","class_counts = train[LABEL_COL].value_counts()\n","labels = sorted(class_counts.index.tolist())\n","class_weights = compute_class_weight('balanced', classes=np.array(labels), y=train[LABEL_COL].dropna().values)\n","\n","# Convert to dictionary for easier mapping\n","weight_dict = dict(zip(labels, class_weights))\n","print(\"Class weights:\", weight_dict)\n","\n","# Convert weights to a tensor in the order of label2id\n","weights_tensor = torch.tensor([weight_dict[label] for label in label2id.keys()], dtype=torch.float32)\n","print(\"Weights tensor:\", weights_tensor)"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1756573735273,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"xB5tdS_O6R_C","outputId":"28d04773-0743-4d57-890b-b7fd9da719f5"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["import torch.nn as nn\n","from transformers import RobertaModel # Import RobertaModel\n","\n","class RobertaWithRating(nn.Module):\n","    def __init__(self, pretrained_model_name=\"roberta-base\", num_labels=2):\n","        super().__init__()\n","        # Load the base RoBERTa model without the classification head\n","        self.roberta = RobertaModel.from_pretrained(pretrained_model_name)\n","        # Get the config for the model to access hidden size\n","        config = self.roberta.config\n","        # Create a new classification head\n","        self.classifier = nn.Sequential(\n","            nn.Linear(config.hidden_size, config.hidden_size),\n","            nn.GELU(),\n","            nn.Dropout(config.hidden_dropout_prob),\n","            nn.Linear(config.hidden_size, num_labels)\n","        )\n","\n","\n","    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n","        # Pass inputs through the RoBERTa model\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","        )\n","        # Get the pooled output (usually the representation of the [CLS] token)\n","        sequence_output = outputs[0]\n","        logits = self.classifier(sequence_output[:, 0, :]) # Use the representation of the first token ([CLS])\n","\n","        loss = None\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.roberta.config.num_labels), labels.view(-1))\n","\n","        return  {\"loss\": loss, \"logits\": logits} # Return a dictionary with loss and logits\n","\n","# model + training args\n","model = RobertaWithRating(pretrained_model_name=\"roberta-base\", num_labels=len(label2id))\n","\n","\n","args = TrainingArguments(\n","    output_dir=\"roberta_run\", per_device_train_batch_size=64, per_device_eval_batch_size=32,\n","    num_train_epochs=10, learning_rate=5e-5, weight_decay=0.01, warmup_ratio=0.06,\n","     save_strategy=\"epoch\", load_best_model_at_end=True,\n","    metric_for_best_model=\"f1_macro\", fp16=True, report_to=\"none\", eval_strategy=\"epoch\",\n","    logging_steps=50 # set the logging steps\n",")"]},{"cell_type":"code","execution_count":95,"metadata":{"executionInfo":{"elapsed":209,"status":"ok","timestamp":1756573860834,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"},"user_tz":-480},"id":"J7rjHMZA6WLO"},"outputs":[],"source":["\n","\n","# Initialize trainer\n","trainer = WeightedTrainer( # Use WeightedTrainer\n","    model=model,\n","    args=args,\n","    train_dataset=train_ds,\n","    eval_dataset=val_ds,\n","    compute_metrics=compute_metrics_fn(id2label),\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n","    class_weights=weights_tensor # Pass class weights\n",")"]},{"cell_type":"code","execution_count":96,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"njsx_VUd6aPc","executionInfo":{"status":"ok","timestamp":1756573892546,"user_tz":-480,"elapsed":31552,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"}},"outputId":"dab3d648-9bee-488b-c692-6c612d61a088"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='150' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [150/500 00:31 < 01:13, 4.73 it/s, Epoch 3/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.156900</td>\n","      <td>0.780464</td>\n","      <td>0.938287</td>\n","      <td>0.852330</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.064200</td>\n","      <td>1.214657</td>\n","      <td>0.930730</td>\n","      <td>0.803820</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.060100</td>\n","      <td>1.226720</td>\n","      <td>0.920655</td>\n","      <td>0.791271</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=150, training_loss=0.09372870127360027, metrics={'train_runtime': 31.4406, 'train_samples_per_second': 1009.84, 'train_steps_per_second': 15.903, 'total_flos': 0.0, 'train_loss': 0.09372870127360027, 'epoch': 3.0})"]},"metadata":{},"execution_count":96}],"source":["\n","# Train the model\n","print(\"Starting training...\")\n","trainer.train()"]},{"cell_type":"code","execution_count":97,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1064f2b","executionInfo":{"status":"ok","timestamp":1756573892688,"user_tz":-480,"elapsed":137,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"}},"outputId":"288010d1-2743-4788-c88d-0c14d9f208f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Making predictions on validation set...\n","\n","Classification Report (Validation Set):\n","                    precision    recall  f1-score   support\n","\n","     Advertisement       0.87      0.81      0.84        16\n","       Good Review       0.97      0.97      0.97       638\n","Irrelevant Content       0.84      0.73      0.78        52\n","              Rant       0.77      0.86      0.81        78\n","              Spam       0.82      0.90      0.86        10\n","\n","          accuracy                           0.94       794\n","         macro avg       0.85      0.85      0.85       794\n","      weighted avg       0.94      0.94      0.94       794\n","\n","\n","Confusion Matrix (Validation Set):\n","[[ 13   0   1   1   1]\n"," [  1 618   2  17   0]\n"," [  0  11  38   2   1]\n"," [  0   7   4  67   0]\n"," [  1   0   0   0   9]]\n"]}],"source":["\n","# Make predictions on validation set\n","print(\"\\nMaking predictions on validation set...\")\n","val_predictions = predict_proba_df(tok, trainer, val, id2label=id2label, text_col=TEXT_COL, max_len=128) # Pass tok and id2label here\n","\n","# Get detailed classification report\n","val_true_labels = val[LABEL_COL].astype(str).tolist()\n","val_pred_labels = val_predictions[\"pred_label\"].tolist()\n","\n","print(\"\\nClassification Report (Validation Set):\")\n","print(classification_report(val_true_labels, val_pred_labels))\n","\n","print(\"\\nConfusion Matrix (Validation Set):\")\n","print(confusion_matrix(val_true_labels, val_pred_labels))"]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4f25276b","executionInfo":{"status":"ok","timestamp":1756573893132,"user_tz":-480,"elapsed":429,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"}},"outputId":"559454ef-15fc-4858-c4a0-99f568c7b75d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Making predictions on test set...\n","\n","Classification Report (Test Set):\n","                    precision    recall  f1-score   support\n","\n","     Advertisement       0.85      0.68      0.76        25\n","       Good Review       0.96      0.96      0.96       774\n","Irrelevant Content       0.80      0.72      0.76        72\n","              Rant       0.74      0.82      0.78       101\n","              Spam       0.84      0.76      0.80        21\n","\n","          accuracy                           0.92       993\n","         macro avg       0.84      0.79      0.81       993\n","      weighted avg       0.92      0.92      0.92       993\n","\n","\n","Confusion Matrix (Test Set):\n","[[ 17   7   0   0   1]\n"," [  0 746   3  24   1]\n"," [  0  14  52   5   1]\n"," [  0   9   9  83   0]\n"," [  3   1   1   0  16]]\n"]}],"source":["# Make predictions on test set\n","print(\"\\nMaking predictions on test set...\")\n","test_predictions = predict_proba_df(tok, trainer, test, id2label=id2label, text_col=TEXT_COL, max_len=128)\n","\n","# Get detailed classification report\n","test_true_labels = test[LABEL_COL].astype(str).tolist()\n","test_pred_labels = test_predictions[\"pred_label\"].tolist()\n","\n","print(\"\\nClassification Report (Test Set):\")\n","print(classification_report(test_true_labels, test_pred_labels))\n","\n","print(\"\\nConfusion Matrix (Test Set):\")\n","print(confusion_matrix(test_true_labels, test_pred_labels))"]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MRK37DOXu37A","executionInfo":{"status":"ok","timestamp":1756573894962,"user_tz":-480,"elapsed":1827,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"}},"outputId":"dc830723-86a0-4ce2-c153-6cacedaedf8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved at roberta_model_with_labels.pth\n","Tokenizer saved at roberta_tokenizer\n","Label mappings saved at label_mappings.pkl\n","Class weights saved at class_weights_tensor.pth\n"]}],"source":["\n","import torch\n","import joblib\n","from transformers import AutoTokenizer\n","\n","# Save the model\n","model_path = \"roberta_model_with_labels.pth\"\n","torch.save(model.state_dict(), model_path)\n","\n","# Save the tokenizer (Hugging Face tokenizers can be saved with save_pretrained)\n","tokenizer_path = \"roberta_tokenizer\"\n","tok.save_pretrained(tokenizer_path)\n","\n","# Save label mappings (label2id and id2label)\n","label_mappings = {\n","    \"label2id\": label2id,\n","    \"id2label\": id2label\n","}\n","with open(\"label_mappings.pkl\", \"wb\") as f:\n","    joblib.dump(label_mappings, f)\n","\n","# Optionally, save class weights if needed\n","class_weights_path = \"class_weights_tensor.pth\"\n","torch.save(weights_tensor, class_weights_path)\n","\n","print(f\"Model saved at {model_path}\")\n","print(f\"Tokenizer saved at {tokenizer_path}\")\n","print(f\"Label mappings saved at label_mappings.pkl\")\n","print(f\"Class weights saved at {class_weights_path}\")"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"65BIUCvk0shE","executionInfo":{"status":"ok","timestamp":1756573894969,"user_tz":-480,"elapsed":4,"user":{"displayName":"xuanlin zhang","userId":"12164217544197760601"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}